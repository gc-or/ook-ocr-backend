"""
LLM æœåŠ¡æ¨¡å—
ä½¿ç”¨ SiliconCloud API (ç¡…åŸºæµåŠ¨) å°† OCR æ–‡æœ¬ç»“æ„åŒ–ä¸ºä¹¦ç±ä¿¡æ¯ JSON
æ”¯æŒ DeepSeekã€Qwen ç­‰å¤šç§æ¨¡å‹
"""
import httpx
import json
import os
import asyncio
from typing import Optional


class LLMService:
    """
    LLM æœåŠ¡ç±»
    è°ƒç”¨ SiliconCloud API è¿›è¡Œæ™ºèƒ½æ–‡æœ¬ç»“æ„åŒ–
    """
    
    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ– LLM æœåŠ¡
        
        Args:
            api_key: SiliconCloud API å¯†é’¥
        """
        self.api_key = api_key or os.getenv("SILICONCLOUD_API_KEY")
        if not self.api_key:
            raise ValueError(
                "âŒ æœªæ‰¾åˆ° SiliconCloud API Keyï¼\n"
                "è¯·è®¾ç½®ç¯å¢ƒå˜é‡: set SILICONCLOUD_API_KEY=ä½ çš„å¯†é’¥"
            )
        
        # SiliconCloud API ç«¯ç‚¹ (å…¼å®¹ OpenAI æ ¼å¼)
        self.api_url = "https://api.siliconflow.cn/v1/chat/completions"
        
        # ä½¿ç”¨ Qwen2.5-7B æ¨¡å‹ (é€Ÿåº¦æ›´å¿«ï¼Œé€‚åˆç»“æ„åŒ–æå–)
        self.model = "Qwen/Qwen2.5-7B-Instruct"
        
        # System Prompt
        self.system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¹¦ç±ä¿¡æ¯æå–åŠ©æ‰‹ã€‚
ç”¨æˆ·ä¼šç»™ä½ ä¸€æ®µä»ä¹¦è„Šå›¾ç‰‡ä¸­ OCR è¯†åˆ«å‡ºçš„åŸå§‹æ–‡æœ¬ï¼ˆå¯èƒ½æœ‰å™ªå£°å’Œé”™è¯¯ï¼‰ã€‚

ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. ä»æ–‡æœ¬ä¸­è¯†åˆ«å‡ºæ‰€æœ‰ä¹¦ç±
2. æå–æ¯æœ¬ä¹¦çš„ä¿¡æ¯å¹¶è¿”å› JSON æ•°ç»„

æ¯æœ¬ä¹¦éœ€è¦æå–ä»¥ä¸‹å­—æ®µ:
- title: ä¹¦å (å¿…å¡«)
- author: ä½œè€… (å¦‚æœèƒ½è¯†åˆ«å‡ºï¼Œå¦åˆ™ä¸º null)
- publisher: å‡ºç‰ˆç¤¾ (å¦‚æœèƒ½è¯†åˆ«å‡ºï¼Œå¦åˆ™ä¸º null)
- edition: ç‰ˆæ¬¡ï¼Œå¦‚"ç¬¬7ç‰ˆ" (å¦‚æœæœ‰ï¼Œå¦åˆ™ä¸º null)
- category: å­¦ç§‘åˆ†ç±»ï¼Œä»ä»¥ä¸‹é€‰é¡¹ä¸­é€‰æ‹©:
  ["é«˜ç­‰æ•°å­¦", "çº¿æ€§ä»£æ•°", "æ¦‚ç‡ç»Ÿè®¡", "å¤§å­¦ç‰©ç†", "ç”µå­ç”µè·¯", "ç¨‹åºè®¾è®¡", "æ•°æ®ç»“æ„", "è®¡ç®—æœºç½‘ç»œ", "å…¶ä»–"]

è¾“å‡ºæ ¼å¼è¦æ±‚:
- å¿…é¡»æ˜¯åˆæ³•çš„ JSON æ•°ç»„
- ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæ–‡å­—ï¼Œåªè¾“å‡ºçº¯ JSON
- å¦‚æœæŸä¸ªå­—æ®µæ— æ³•è¯†åˆ«ï¼Œè®¾ä¸º null"""

    async def extract_book_info(self, ocr_text: str, max_retries: int = 3) -> list[dict]:
        """
        ä» OCR æ–‡æœ¬ä¸­æå–ä¹¦ç±ä¿¡æ¯
        
        Args:
            ocr_text: OCR è¯†åˆ«å‡ºçš„åŸå§‹æ–‡æœ¬
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            
        Returns:
            list[dict]: ä¹¦ç±ä¿¡æ¯åˆ—è¡¨
        """
        # OpenAI å…¼å®¹æ ¼å¼çš„è¯·æ±‚ä½“
        payload = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": f"è¯·ä»ä»¥ä¸‹ OCR æ–‡æœ¬ä¸­æå–ä¹¦ç±ä¿¡æ¯ï¼š\n\n{ocr_text}"}
            ],
            "temperature": 0.1,
            "max_tokens": 2000
        }
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # é‡è¯•æœºåˆ¶
        for attempt in range(max_retries):
            try:
                async with httpx.AsyncClient(timeout=60.0) as client:
                    response = await client.post(
                        self.api_url,
                        json=payload,
                        headers=headers
                    )
                    
                    # å¤„ç†é€Ÿç‡é™åˆ¶ (429)
                    if response.status_code == 429:
                        wait_time = (attempt + 1) * 2
                        print(f"â³ API é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯• ({attempt + 1}/{max_retries})...")
                        await asyncio.sleep(wait_time)
                        continue
                    
                    response.raise_for_status()
                    result = response.json()
                    
                    # è§£æ OpenAI æ ¼å¼è¿”å›
                    content = result["choices"][0]["message"]["content"]
                    return self._parse_json_response(content)
                    
            except httpx.HTTPStatusError as e:
                print(f"âš ï¸ HTTP é”™è¯¯: {e.response.status_code}")
                if attempt < max_retries - 1:
                    print(f"   é‡è¯•ä¸­... ({attempt + 1}/{max_retries})")
                    await asyncio.sleep(2)
                else:
                    raise e
            except Exception as e:
                print(f"âš ï¸ è¯·æ±‚é”™è¯¯: {e}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(2)
                else:
                    raise e
        
        return []
    
    def _parse_json_response(self, content: str) -> list[dict]:
        """è§£æ LLM è¿”å›çš„ JSON"""
        content = content.strip()
        # æ¸…ç† markdown ä»£ç å—æ ‡è®°
        if content.startswith("```json"):
            content = content[7:]
        if content.startswith("```"):
            content = content[3:]
        if content.endswith("```"):
            content = content[:-3]
        content = content.strip()
        
        try:
            books = json.loads(content)
            return books if isinstance(books, list) else [books]
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSON è§£æå¤±è´¥: {e}")
            print(f"åŸå§‹è¿”å›: {content}")
            return []


# å…¨å±€å®ä¾‹
_llm_service: Optional[LLMService] = None

def get_llm_service() -> LLMService:
    """è·å– LLM æœåŠ¡å®ä¾‹"""
    global _llm_service
    if _llm_service is None:
        _llm_service = LLMService()
    return _llm_service


# ============ æµ‹è¯•ä»£ç  ============
if __name__ == "__main__":
    import asyncio
    
    test_ocr_text = """
ç”µå­æŠ€æœ¯åŸºç¡€æ•°å­—éƒ¨åˆ†ï¼ˆç¬¬7ç‰ˆï¼‰
ä¸»ç¼–åº·åå…‰å¼ æ—
æ•°å­—ä¿¡å·å¤„ç†
ç¬¬3ç‰ˆ
ç¨‹åºè®¾è®¡æ•™ç¨‹ ç”¨CC++è¯­è¨€ç¼–ç¨‹
æ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡ï¼ˆç¬¬ä¸‰ç‰ˆ
"""
    
    async def main():
        print("ğŸ¤– æµ‹è¯• SiliconCloud LLM ç»“æ„åŒ–æå–...")
        print(f"è¾“å…¥æ–‡æœ¬:\n{test_ocr_text}")
        print("-" * 40)
        
        try:
            llm = get_llm_service()
            books = await llm.extract_book_info(test_ocr_text)
            
            print("\nğŸ“š æå–ç»“æœ:")
            print(json.dumps(books, ensure_ascii=False, indent=2))
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
    
    asyncio.run(main())
